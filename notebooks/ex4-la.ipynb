{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c65deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Jupyter Starter Pack ---\n",
    "\n",
    "# autoreload: refresh code on every cell run\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# clean warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# numpy / pandas nicer display\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# matplotlib defaults\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "# tqdm in notebooks\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# optional: make exceptions show only the important frame\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e13b03df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unet import UNetModel\n",
    "from train_score import marginal_prob_std, diffusion_coeff\n",
    "import torch\n",
    "import functools\n",
    "\n",
    "device = 'cuda'\n",
    "sigma =  25.0\n",
    "\n",
    "cfg = {\n",
    "\t\"model\": {\n",
    "\t\t\"in_channels\": 1,\n",
    "\t\t\"out_channels\": 1,\n",
    "\t\t\"model_channels\": 32,\n",
    "\t\t\"channel_mult\": [1, 2, 4],\n",
    "\t\t\"num_res_blocks\": 1,\n",
    "\t\t\"attention_resolutions\": [],\n",
    "\t\t\"max_period\": 0.005,\n",
    "\t},\n",
    "}\n",
    "\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma, device=device)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma, device=device)\n",
    "UNet_model = UNetModel(marginal_prob_std=marginal_prob_std_fn, **cfg[\"model\"])\n",
    "\n",
    "score_model = UNet_model.to(device)\n",
    "score_model.load_state_dict(torch.load('ckpt.pt', map_location=device))\n",
    "score_model.eval()\n",
    "\n",
    "from cnet import Net\n",
    "classifier = Net().to(device)\n",
    "classifier.load_state_dict(torch.load('cnet.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "800d815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "\t\"control_net\": {\n",
    "\t\t\"in_channels\": 2,\n",
    "\t\t\"out_channels\": 1,\n",
    "\t\t\"model_channels\": 32,\n",
    "\t\t\"channel_mult\": [1, 2],\n",
    "\t\t\"num_res_blocks\": 1,\n",
    "\t\t\"attention_resolutions\": [],\n",
    "\t\t\"max_period\": 0.005,\n",
    "\t},\n",
    "}\n",
    "\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma, device=device)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma, device=device)\n",
    "control_net_1 = UNetModel(marginal_prob_std=marginal_prob_std_fn, **cfg[\"control_net\"]).to(device)\n",
    "control_net_2 = UNetModel(marginal_prob_std=marginal_prob_std_fn, **cfg[\"control_net\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98d3ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LearnableAggregator(nn.Module):\n",
    "    def __init__(self, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(32, 64)\n",
    "        )\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.norm = nn.GroupNorm(8, 64)\n",
    "        \n",
    "        self.final = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "        nn.init.zeros_(self.final.weight)\n",
    "        nn.init.zeros_(self.final.bias)\n",
    "\n",
    "    def forward(self, x1, x2, t):\n",
    "        \"\"\"\n",
    "        x1, x2: [Batch, 1, 28, 28]\n",
    "        t: [Batch]\n",
    "        \"\"\"\n",
    "        y_base = x1 + x2\n",
    "        \n",
    "        inp = torch.cat([x1, x2], dim=1)\n",
    "        \n",
    "        t_emb = self.time_mlp(t[:, None])\n",
    "        t_emb = t_emb[:, :, None, None]\n",
    "        \n",
    "        h = F.silu(self.conv1(inp))\n",
    "        h = h + t_emb # Add time info\n",
    "        h = self.norm(h)\n",
    "        h = F.silu(self.conv2(h))\n",
    "        \n",
    "        delta_y = self.final(h)\n",
    "       \n",
    "        return y_base + delta_y\n",
    "\n",
    "\n",
    "image_model = LearnableAggregator(device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59f40104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LearnableAggregator(nn.Module):\n",
    "    def __init__(self, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(32, 64)\n",
    "        )\n",
    "        \n",
    "        # Feature trunk\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.norm = nn.GroupNorm(8, 64)\n",
    "        \n",
    "        # Attention logits over {x1, x2}\n",
    "        self.att_head = nn.Conv2d(64, 2, kernel_size=1)\n",
    "\n",
    "        # Optional extra residual refinement\n",
    "        self.delta_head = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        nn.init.zeros_(self.delta_head.weight)\n",
    "        nn.init.zeros_(self.delta_head.bias)\n",
    "\n",
    "        # Make attention start as equal weights -> w1 = w2 = 0.5\n",
    "        nn.init.zeros_(self.att_head.weight)\n",
    "        nn.init.zeros_(self.att_head.bias)\n",
    "\n",
    "    def forward(self, x1, x2, t):\n",
    "        \"\"\"\n",
    "        x1, x2: [B, 1, H, W]\n",
    "        t: [B]\n",
    "        \"\"\"\n",
    "        t = t.to(x1.device).float()\n",
    "\n",
    "        y_base = x1 + x2\n",
    "\n",
    "        inp = torch.cat([x1, x2], dim=1)  # [B, 2, H, W]\n",
    "\n",
    "        t_emb = self.time_mlp(t[:, None])    # [B, 64]\n",
    "        t_emb = t_emb[:, :, None, None]      # [B, 64, 1, 1]\n",
    "\n",
    "        h = F.silu(self.conv1(inp))\n",
    "        h = h + t_emb\n",
    "        h = self.norm(h)\n",
    "        h = F.silu(self.conv2(h))\n",
    "\n",
    "        att_logits = self.att_head(h)             # [B, 2, H, W]\n",
    "        att_weights = F.softmax(att_logits, dim=1)  # [B, 2, H, W]\n",
    "\n",
    "        w1 = att_weights[:, 0:1]  # [B,1,H,W]\n",
    "        w2 = att_weights[:, 1:2]\n",
    "\n",
    "        mix_residual = (w1 - 0.5) * x1 + (w2 - 0.5) * x2\n",
    "\n",
    "        delta_y = self.delta_head(h)\n",
    "\n",
    "        return y_base + mix_residual + delta_y\n",
    "\n",
    "image_model = LearnableAggregator(device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c6877bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Controlled_Euler_Maruyama_sampler(\n",
    "    score_model,\n",
    "    control_net_1,\n",
    "    control_net_2,\n",
    "    image_model,\n",
    "    marginal_prob_std,\n",
    "    diffusion_coeff,\n",
    "    batch_size=8,\n",
    "    num_steps=500,\n",
    "    device='cuda',\n",
    "    eps=1e-3\n",
    "):\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    \n",
    "    # Initialize separate latent codes\n",
    "    x1 = torch.randn(batch_size, 1, 28, 28, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
    "    x2 = torch.randn(batch_size, 1, 28, 28, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
    "    \n",
    "    mask_top = torch.zeros((1, 1, 28, 28), device=device); mask_top[:, :, :14, :] = 1.0\n",
    "    mask_bot = torch.zeros((1, 1, 28, 28), device=device); mask_bot[:, :, 14:, :] = 1.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for time_step in range(len(time_steps)):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_steps[time_step]\n",
    "    \n",
    "            g = diffusion_coeff(batch_time_step)\n",
    "            g_sq = (g**2)[:, None, None, None]\n",
    "            \n",
    "            Y_t = image_model(x1, x2, batch_time_step)\n",
    "            \n",
    "            u1 = control_net_1(torch.cat([x1, Y_t], dim=1), batch_time_step)\n",
    "            u2 = control_net_2(torch.cat([x2, Y_t], dim=1), batch_time_step)\n",
    "                        \n",
    "            drift1 = g_sq * score_model(x1, batch_time_step)\n",
    "            x1 = x1 + (drift1 + u1) * step_size + torch.sqrt(step_size) * g[:,None,None,None] * torch.randn_like(x1)\n",
    "            \n",
    "            drift2 = g_sq * score_model(x2, batch_time_step)\n",
    "            x2 = x2 + (drift2 + u2) * step_size + torch.sqrt(step_size) * g[:,None,None,None] * torch.randn_like(x2)\n",
    "    \n",
    "    return image_model(x1, x2, torch.ones(batch_size, device=device) * eps).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e258b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_and_plot_samples(\n",
    "    score_model,\n",
    "    control_net_1,\n",
    "    control_net_2,\n",
    "    image_model,\n",
    "    classifier,\n",
    "    marginal_prob_std_fn,\n",
    "    diffusion_coeff_fn,\n",
    "    sample_batch_size=64,\n",
    "    num_steps=500,\n",
    "    device='cuda',\n",
    "    eps=1e-3,\n",
    "):\n",
    "    \"\"\"Generate samples using Controlled Euler-Maruyama and plot with predicted class labels.\"\"\"\n",
    "\n",
    "    # eval mode\n",
    "    score_model.eval()\n",
    "    control_net_1.eval()\n",
    "    control_net_2.eval()\n",
    "    classifier.eval()\n",
    "    image_model.eval()\n",
    "\n",
    "    # sampling\n",
    "    samples = Controlled_Euler_Maruyama_sampler(\n",
    "        score_model,\n",
    "        control_net_1,\n",
    "        control_net_2,\n",
    "        image_model,\n",
    "        marginal_prob_std_fn,\n",
    "        diffusion_coeff_fn,\n",
    "        batch_size=sample_batch_size,\n",
    "        num_steps=num_steps,\n",
    "        device=device,\n",
    "        eps=eps\n",
    "    )\n",
    "\n",
    "    samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "    # classify\n",
    "    with torch.no_grad():\n",
    "        logits = classifier(samples.to(device))\n",
    "        preds = logits.argmax(dim=1).cpu()\n",
    "\n",
    "    # grid size\n",
    "    B = samples.size(0)\n",
    "    nrow = int(np.sqrt(B))\n",
    "    ncol = int(np.ceil(B / nrow))\n",
    "\n",
    "    # plotting\n",
    "    _, axes = plt.subplots(nrow, ncol, figsize=(6, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < B:\n",
    "            img = samples[i].cpu().squeeze(0)\n",
    "            ax.imshow(img, cmap='gray', vmin=0., vmax=1.)\n",
    "            ax.set_title(str(preds[i].item()), fontsize=8)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return samples, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "084a9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tv_loss(img):\n",
    "    \"\"\"\n",
    "    Computes Total Variation Loss (penalizes high-frequency noise).\n",
    "    img: [Batch, Channels, H, W]\n",
    "    \"\"\"\n",
    "    # vertical differences\n",
    "    h_diff = img[:, :, 1:, :] - img[:, :, :-1, :]\n",
    "    # horizontal differences\n",
    "    w_diff = img[:, :, :, 1:] - img[:, :, :, :-1]\n",
    "    \n",
    "    # Sum of absolute differences\n",
    "    return torch.mean(torch.abs(h_diff)) + torch.mean(torch.abs(w_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63dcc83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training control policy:   0%|          | 0/1000 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 164\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# ----- update player 1 given player 0 fixed -----\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(INNER_ITERS):\n\u001b[0;32m--> 164\u001b[0m     loss2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_control_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontrol_net_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontrol_net_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmarginal_prob_std_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiffusion_coeff_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_digit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLAMBDA_REG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplayer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss1\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss2\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[47], line 126\u001b[0m, in \u001b[0;36mtrain_control_policy\u001b[0;34m(score_model, classifier, control_net_1, control_net_2, image_model, marginal_prob_std, diffusion_coeff, optimizer, target_digit, num_steps, batch_size, device, eps, lambda_reg, running_class_reg, player_idx)\u001b[0m\n\u001b[1;32m    118\u001b[0m tv_loss \u001b[38;5;241m=\u001b[39m calculate_tv_loss(Y_0_hat)\n\u001b[1;32m    121\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m (lambda_reg \u001b[38;5;241m*\u001b[39m cumulative_control_loss) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    122\u001b[0m              class_loss \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    123\u001b[0m              (running_class_reg \u001b[38;5;241m*\u001b[39m cumulative_class_loss) \\\n\u001b[1;32m    124\u001b[0m              \u001b[38;5;241m+\u001b[39m tv_loss\n\u001b[0;32m--> 126\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(control_net_1\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    129\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(control_net_2\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/home/git/multi-agent-diffusion-working-repo/.venv/lib/python3.10/site-packages/torch/_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/home/git/multi-agent-diffusion-working-repo/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/home/git/multi-agent-diffusion-working-repo/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "# PARAMETERS\n",
    "NUM_STEPS = 500\n",
    "BATCH_SIZE = 16\n",
    "OUTER_ITERS = 1000\n",
    "INNER_ITERS = 1\n",
    "LAMBDA_REG = 0.01\n",
    "\n",
    "def train_control_policy(\n",
    "    score_model,\n",
    "    classifier,\n",
    "    control_net_1,\n",
    "    control_net_2,\n",
    "    image_model,\n",
    "    marginal_prob_std,\n",
    "    diffusion_coeff,\n",
    "    optimizer,\n",
    "    target_digit=0,\n",
    "    num_steps=100,\n",
    "    batch_size=64,\n",
    "    device='cuda',\n",
    "    eps=1e-3,\n",
    "    lambda_reg=0.1,      # Cost of using control\n",
    "    running_class_reg=1.0, # New: Weight for the running classifier loss\n",
    "    player_idx=0,\n",
    "):   \n",
    "    \"\"\"Train one control policy given the other is fixed.\"\"\"\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    \n",
    "    def get_std(time_tensor):\n",
    "        return marginal_prob_std(time_tensor)[:, None, None, None]\n",
    "\n",
    "    init_x1 = torch.randn(batch_size, 1, 28, 28, device=device) * get_std(t)\n",
    "    init_x2 = torch.randn(batch_size, 1, 28, 28, device=device) * get_std(t)\n",
    "    \n",
    "    x1 = init_x1\n",
    "    x2 = init_x2\n",
    "    \n",
    "    # Overlap logic\n",
    "    mid = 14\n",
    "    start_overlap = mid - (4 // 2) # 12\n",
    "    end_overlap   = mid + (4 // 2) # 16\n",
    "\n",
    "    mask_top = torch.zeros((1, 1, 28, 28), device=device)\n",
    "    mask_top[:, :, :end_overlap, :] = 1.0\n",
    "    \n",
    "    mask_bot = torch.zeros((1, 1, 28, 28), device=device)\n",
    "    mask_bot[:, :, start_overlap:, :] = 1.0\n",
    "\n",
    "    cumulative_control_loss = 0\n",
    "    cumulative_class_loss = 0\n",
    "\n",
    "    for time_step in range(len(time_steps)):\n",
    "        batch_time_step = torch.ones(batch_size, device=device) * time_steps[time_step]\n",
    "        \n",
    "        g = diffusion_coeff(batch_time_step)\n",
    "        g_sq = (g**2)[:, None, None, None]\n",
    "        g_noise = g[:, None, None, None]\n",
    "        \n",
    "        Y_t = image_model(x1, x2, batch_time_step)\n",
    "        \n",
    "        if player_idx == 0:\n",
    "            u1 = control_net_1(torch.cat([x1, Y_t], dim=1), batch_time_step)\n",
    "            with torch.no_grad():\n",
    "                u2 = control_net_2(torch.cat([x2, Y_t], dim=1), batch_time_step)\n",
    "        elif player_idx == 1:\n",
    "            with torch.no_grad():\n",
    "                u1 = control_net_1(torch.cat([x1, Y_t], dim=1), batch_time_step)\n",
    "            u2 = control_net_2(torch.cat([x2, Y_t], dim=1), batch_time_step)\n",
    "        else:\n",
    "            raise ValueError(\"player_idx must be 0 or 1 - Python indexing\")\n",
    "\n",
    "        current_std = get_std(batch_time_step)\n",
    "        \n",
    "        s1 = score_model(x1, batch_time_step)\n",
    "        s2 = score_model(x2, batch_time_step)\n",
    "        \n",
    "        x1_0_hat = x1 + (current_std ** 2) * s1\n",
    "        x2_0_hat = x2 + (current_std ** 2) * s2\n",
    "        \n",
    "        Y_0_hat = image_model(x1_0_hat, x2_0_hat, batch_time_step)\n",
    "        running_tv_loss = calculate_tv_loss(Y_0_hat)\n",
    "        # range_loss = torch.mean(torch.relu(torch.abs(Y_0_hat) - 1.0))\n",
    "\n",
    "\n",
    "        logits_running = classifier(Y_0_hat)\n",
    "        target_labels = torch.full((batch_size,), target_digit, device=device, dtype=torch.long)\n",
    "        \n",
    "        running_loss = F.cross_entropy(logits_running, target_labels)\n",
    "        cumulative_class_loss += (running_loss + running_tv_loss) * step_size\n",
    "        # print(f\"Time step {time_step}/{len(time_steps)}: Running loss {running_loss.item():.4f}, TV loss {running_tv_loss.item():.4f}, Range loss {range_loss.item():.4f}\")\n",
    "\n",
    "        drift1 = g_sq * s1 \n",
    "        mean_x1 = x1 + (drift1 + u1) * step_size\n",
    "        x1 = mean_x1 + torch.sqrt(step_size) * g_noise * torch.randn_like(x1)\n",
    "        \n",
    "        drift2 = g_sq * s2 \n",
    "        mean_x2 = x2 + (drift2 + u2) * step_size\n",
    "        x2 = mean_x2 + torch.sqrt(step_size) * g_noise * torch.randn_like(x2)\n",
    "        if player_idx == 0:\n",
    "            cumulative_control_loss += torch.mean(u1**2) * step_size\n",
    "        elif player_idx == 1:\n",
    "            cumulative_control_loss += torch.mean(u2**2) * step_size\n",
    "        else: \n",
    "            raise ValueError(\"player_idx must be 0 or 1 - Python indexing\")\n",
    "\n",
    "    Y_final = image_model(x1, x2, torch.ones(batch_size, device=device) * eps)\n",
    "    logits = classifier(Y_final)\n",
    "    target_labels = torch.full((batch_size,), target_digit, device=device, dtype=torch.long)\n",
    "    class_loss = F.cross_entropy(logits, target_labels)\n",
    "    tv_loss = calculate_tv_loss(Y_0_hat)\n",
    "\n",
    "\n",
    "    total_loss = (lambda_reg * cumulative_control_loss) + \\\n",
    "                 class_loss + \\\n",
    "                 (running_class_reg * cumulative_class_loss) \\\n",
    "                 + tv_loss\n",
    "                 \n",
    "    total_loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(control_net_1.parameters(), 1.0)\n",
    "    torch.nn.utils.clip_grad_norm_(control_net_2.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "opt1 = torch.optim.Adam(list(control_net_1.parameters()) + list(image_model.parameters()), lr=1e-4)\n",
    "opt2 = torch.optim.Adam(list(control_net_2.parameters()) + list(image_model.parameters()), lr=1e-4)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pbar = tqdm(range(OUTER_ITERS), desc=\"Training control policy\")\n",
    "for epoch in pbar:\n",
    "    # ----- update player 0 given player 1 fixed -----\n",
    "    for i in range(INNER_ITERS):\n",
    "        loss1 = train_control_policy(\n",
    "            score_model,\n",
    "            classifier,\n",
    "            control_net_1,\n",
    "            control_net_2,\n",
    "            image_model,\n",
    "            marginal_prob_std_fn,\n",
    "            diffusion_coeff_fn,\n",
    "            opt1,\n",
    "            target_digit=0,\n",
    "            num_steps=25,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            device=device,\n",
    "            eps=1e-3,\n",
    "            lambda_reg=LAMBDA_REG,\n",
    "            player_idx=0,\n",
    "        )\n",
    "    # ----- update player 1 given player 0 fixed -----\n",
    "    for i in range(INNER_ITERS):\n",
    "        loss2 = train_control_policy(\n",
    "            score_model,\n",
    "            classifier,\n",
    "            control_net_1,\n",
    "            control_net_2,\n",
    "            image_model,\n",
    "            marginal_prob_std_fn,\n",
    "            diffusion_coeff_fn,\n",
    "            opt2,\n",
    "            target_digit=0,\n",
    "            num_steps=25,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            device=device,\n",
    "            eps=1e-3,\n",
    "            lambda_reg=LAMBDA_REG,\n",
    "            player_idx=1,\n",
    "        )\n",
    "    pbar.set_postfix(loss=f\"{loss1.item():.4f}, {loss2.item():.4f}\")\n",
    "    if epoch % 10 == 0:\n",
    "        generate_and_plot_samples(\n",
    "            score_model,\n",
    "            control_net_1,\n",
    "            control_net_2,\n",
    "            image_model,\n",
    "            classifier,\n",
    "            marginal_prob_std_fn,\n",
    "            diffusion_coeff_fn,\n",
    "            sample_batch_size=64,\n",
    "            num_steps=500,\n",
    "            device='cuda'\n",
    "        )\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(control_net_1.state_dict(), \"control_net_1_0_fits.pt\")\n",
    "torch.save(control_net_2.state_dict(), \"control_net_2_0_fits.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "score_model.eval()\n",
    "control_net_1.eval()\n",
    "control_net_2.eval()\n",
    "\n",
    "sample_batch_size = 64\n",
    "samples = Controlled_Euler_Maruyama_sampler(\n",
    "    score_model,\n",
    "    control_net_1,\n",
    "    control_net_2,\n",
    "    marginal_prob_std_fn,\n",
    "    diffusion_coeff_fn,\n",
    "    batch_size=sample_batch_size,\n",
    "    num_steps=500,\n",
    "    device='cuda',\n",
    "    eps=1e-3\n",
    ")\n",
    "\n",
    "samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    logits = classifier(samples.to(device))      # (B, num_classes)\n",
    "    preds = logits.argmax(dim=1).cpu()          # (B,)\n",
    "\n",
    "B = samples.size(0)\n",
    "nrow = int(np.sqrt(B))\n",
    "ncol = int(np.ceil(B / nrow))\n",
    "\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(6, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < B:\n",
    "        img = samples[i].cpu().squeeze(0)       # (H, W) for 1-channel\n",
    "        ax.imshow(img, cmap='gray', vmin=0., vmax=1.)\n",
    "        ax.set_title(str(preds[i].item()), fontsize=8)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
